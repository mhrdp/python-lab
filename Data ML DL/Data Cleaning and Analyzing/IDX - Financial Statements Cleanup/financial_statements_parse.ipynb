{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"financial_statements_parse.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1sJQ6dXxFjR9-sJkTma9KDVRKI6W8VfB9","authorship_tag":"ABX9TyO/Tf7Cg+s1S6VzPwTPyQnR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import csv\n","import os\n","\n","import pandas as pd\n","\n","class ExtractData:\n","    def __init__(self, file_in):\n","        self.file_in = file_in\n","        self.file_out = None\n","    \n","    @staticmethod\n","    def _get_company_name(file_in):\n","        reader = pd.read_excel(file_in, sheet_name='1000000')\n","        dict_temp = {}\n","\n","        for i in range(len(reader)):\n","            key = reader['Unnamed: 2'][i]\n","            val = reader['Unnamed: 1'][i]\n","            dict_temp[key] = [val]\n","        \n","        df = pd.DataFrame(dict_temp)\n","        df = df.rename(\n","            columns = {\n","                'Entity code': 'entity_code',\n","                'Level of rounding used in financial statements': 'rounding_level',\n","            }\n","        )\n","\n","        # Use __getitem__ method, aka. [[...]] to return type DataFrame, instead of series\n","        return df[['entity_code', 'rounding_level']]\n","        \n","    def general_inf(self):\n","        file_in = self.file_in\n","        self.file_out = '/content/drive/MyDrive/Program/Python/Data ML DL/Data Cleaning and Analyzing/IDX - Financial Statements Cleanup/company_general_information.csv'\n","        \n","        # index_col=0 is to remove auto-generated index column\n","        gen_inf = pd.read_excel(file_in, sheet_name='1000000', index_col=0)\n","        gen_inf_dict = {}\n","        \n","        for i in range(len(gen_inf)):\n","            key = gen_inf['Unnamed: 2'][i]\n","            val = gen_inf['Unnamed: 1'][i]\n","            gen_inf_dict[key] = [val]\n","        \n","        df = pd.DataFrame(gen_inf_dict)\n","\n","        # Rename the first dataframe header\n","        df.columns.values[0] = 'date_of_report'\n","        df = df.rename(columns={\n","            'Entity name': 'entity_name',\n","            'Entity code': 'entity_code',\n","            'Explanation of change in name from the end of the preceding reporting period': 'name_change_explanation',\n","            'Entity identification number': 'identification_number',\n","            'Entity main industry': 'main_industry',\n","            'Controlling shareholder information': 'information_control',\n","            'Type of entity': 'entity_type',\n","            'Type of listed securities': 'securities_type',\n","            'Type of board on which the entity is listed': 'type_of_board',\n","            'Whether the financial statements are of an individual entity or a group of entities': 'statements_from',\n","            'Period of financial statements submissions': 'period',\n","            'Current period start date': 'start_date',\n","            'Current period end date': 'end_date',\n","            'Prior period start date': 'prior_start_date',\n","            'Prior period end date': 'prior_end_date',\n","            'Description of presentation currency': 'currency',\n","            'Conversion rate at reporting date if presentation currency is other than rupiah': 'alternate_currency',\n","            'Level of rounding used in financial statements': 'rounding_level',\n","            'Type of report on financial statements': 'report_type',\n","            'Type of auditor\\'s opinion': 'auditor_opinion_type',\n","            'Matters disclosed in emphasis-of-matter or other-matter paragraph, if any': 'emphasis_of_matter',\n","            'Result of review engagement': 'review_result',\n","            'Date of auditor\\'s opinion or result of review report': 'date_of_review',\n","            'Name of current year audit signing partner': 'signing_partner_name',\n","            'Number of years served as audit signing partner': 'signing_partner_experience',\n","            'Name of prior year audit signing partner': 'prior_year_signing_partner',\n","            'Whether in compliance with BAPEPAM LK VIII G 11 rules concerning responsibilities of board of directors on financial statements': 'BAPEPAM_LK_VIII_G11',\n","            'Whether in compliance with BAPEPAM LK VIII A two rules concerning independence of accountant providing audit services in capital market': 'BAPEPAM_LK_VIII_A2',\n","\n","            'Sector': 'sector',\n","            'Subsector': 'subsector',\n","            'Prior year end date': 'prior_year_end',\n","            'Current year auditor': 'current_year_auditor',\n","            'Prior year auditor': 'prior_year_auditor',\n","        })\n","        df = df.drop(columns=['General information'])\n","\n","        if os.path.exists(self.file_out):\n","            count = 0\n","            read_file_out = pd.read_csv(self.file_out)\n","\n","            if df['entity_code'][0] not in list(read_file_out['entity_code']):\n","                # mode = 'a' is to append, default is 'w' to write\n","                df.to_csv('./company_general_information.csv', mode='a', header=False, index=False)\n","\n","            for j in range(len(read_file_out)):\n","                # Use .iloc[] so the DataFrame can accept negative index\n","                if df['entity_code'][0] == read_file_out['entity_code'].iloc[j]:\n","                    if df['end_date'][0] == read_file_out['end_date'][j]:\n","                        count += 1\n","\n","            if count == 0:\n","                df.to_csv('./company_general_information.csv', mode='a', header=False, index=False)\n","        else:\n","            df.to_csv('./company_general_information.csv', index=False)\n","    \n","    def financial_pos(self):\n","        fin_pos = pd.read_excel(self.file_in, sheet_name='1210000', index_col=0)\n","        self.file_out = '/content/drive/MyDrive/Program/Python/Data ML DL/Data Cleaning and Analyzing/IDX - Financial Statements Cleanup/company_financial_position.csv'\n","\n","        header = []\n","        content = []\n","        fin_dict = {}\n","\n","        df_get_name = self._get_company_name(self.file_in)\n","\n","        for i in range(len(fin_pos)):\n","            key = fin_pos['Unnamed: 3'][i]\n","            val = fin_pos['Unnamed: 1'][i]\n","            # The val need to be encapsulated inside a list\n","            fin_dict[key] = [val]\n","\n","        df_temp = pd.DataFrame(fin_dict)\n","        df_temp.columns.values[0] = 'date_of_report'\n","\n","        # Slice the dataframe with __getitem__ method aka. [[...]]\n","        df_trim = df_temp[[\n","                'date_of_report', 'Total current assets', 'Total non-current assets', 'Total assets',\n","                'Total current liabilities', 'Total non-current liabilities', 'Total liabilities',\n","                'Total equity', 'Total liabilities and equity',\n","        ]]\n","        df_trim = df_trim.rename(\n","            columns = {\n","                'Total current assets': 'total_current_assets',\n","                'Total non-current assets': 'total_noncurrent_assets',\n","                'Total assets': 'total_assets',\n","                'Total current liabilities': 'total_current_liabilities',\n","                'Total non-current liabilities': 'total_noncurrent_liabilities',\n","                'Total liabilities': 'total_liabilities',\n","                'Total equity': 'total_equity',\n","                'Total liabilities and equity': 'total_liabilities_and_equity',\n","            }\n","        )\n","\n","        # axis=1 was to combine the DataFrames according to its index,\n","        # instead of making new row for each data inside the DataFrames like the default behaviour\n","        df = pd.concat([df_get_name, df_trim], axis=1)\n","\n","        if os.path.exists(self.file_out):\n","            count = 0\n","            read_file_out = pd.read_csv(self.file_out)\n","\n","            if df['entity_code'][0] not in list(read_file_out['entity_code']):\n","                # mode = 'a' is to append, default is 'w' to write\n","                df.to_csv('./company_financial_position.csv', mode='a', header=False, index=False)\n","\n","            for j in range(len(read_file_out)):\n","                # Use .iloc[] so the DataFrame can accept negative index\n","                if df['entity_code'][0] == read_file_out['entity_code'].iloc[j]:\n","                    if df['date_of_report'][0] == read_file_out['date_of_report'][j]:\n","                        count += 1\n","\n","            if count == 0:\n","                df.to_csv('./company_financial_position.csv', mode='a', header=False, index=False)\n","        else:\n","            df.to_csv('./company_financial_position.csv', index=False)\n","\n","file_in_1 = '/content/drive/MyDrive/Program/Python/Data ML DL/Datasets/IDX - Financial Statements/ABBA/FinancialStatement-2021-I-ABBA.xlsx'\n","file_in_2 = '/content/drive/MyDrive/Program/Python/Data ML DL/Datasets/IDX - Financial Statements/AALI/FinancialStatement-2021-I-AALI.xlsx'\n","file_in_3 = '/content/drive/MyDrive/Program/Python/Data ML DL/Datasets/IDX - Financial Statements/AALI/FinancialStatement-2021-II-AALI.xlsx'\n","init = ExtractData(file_in_3)\n","init.financial_pos()"],"metadata":{"id":"dWKJS5lie-ZS","executionInfo":{"status":"ok","timestamp":1639899519200,"user_tz":-420,"elapsed":966,"user":{"displayName":"Mahardhika Dwi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18064939782869251856"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["!cp company_financial_position.csv \"/content/drive/MyDrive/Program/Python/Data ML DL/Data Cleaning and Analyzing/IDX - Financial Statements Cleanup\""],"metadata":{"id":"ABy1hnOqKgGM","executionInfo":{"status":"ok","timestamp":1639899531845,"user_tz":-420,"elapsed":11,"user":{"displayName":"Mahardhika Dwi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18064939782869251856"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import csv\n","import os\n","\n","FILENAME = \"/content/drive/MyDrive/Program/Python/Data ML DL/Datasets/IDX - Financial Statements/AALI/FinancialStatement-2021-II-AALI.xlsx\"\n","fin_pos = pd.read_excel(FILENAME, sheet_name='1210000', index_col=0)\n","header = []\n","content = []\n","fin_dict = {}\n","\n","for i in range(len(fin_pos)):\n","    key = fin_pos['Unnamed: 3'][i]\n","    val = fin_pos['Unnamed: 1'][i]\n","    # The val need to be encapsulated inside a list\n","    fin_dict[key] = [val]\n","\n","df = pd.DataFrame(fin_dict)\n","df.columns.values[0] = 'date_of_report'\n","\n","df_trim = df[[\n","        'date_of_report', 'Total current assets', 'Total non-current assets', 'Total assets',\n","        'Total current liabilities', 'Total non-current liabilities', 'Total liabilities',\n","        'Total equity', 'Total liabilities and equity',\n","]]\n","\n","CSV_FILE = '/content/drive/MyDrive/Program/Python/Data ML DL/Data Cleaning and Analyzing/IDX - Financial Statements Cleanup/company_financial_position.csv'\n","\n","read_csv = pd.read_csv(CSV_FILE)\n","read_csv['entity_code'][0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"FofAzNC8qGEA","executionInfo":{"status":"ok","timestamp":1639896929918,"user_tz":-420,"elapsed":1143,"user":{"displayName":"Mahardhika Dwi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18064939782869251856"}},"outputId":"a012c24d-894a-4c4a-ff8a-ab3b240165bf"},"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'AALI'"]},"metadata":{},"execution_count":44}]},{"cell_type":"markdown","source":["# Using `pandas` Library\n","Before export it to `.csv`, we need to convert the data into `pandas` `DataFrame` format."],"metadata":{"id":"m-IcLKkYbdgW"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"MWBH9sSiRS5C"},"outputs":[],"source":["import pandas as pd\n","import csv\n","import os\n","\n","FILENAME = \"/content/drive/MyDrive/Program/Python/Data ML DL/Datasets/IDX - Financial Statements/AALI/FinancialStatement-2021-I-AALI.xlsx\"\n","general_inf = pd.read_excel(FILENAME, sheet_name='1000000', index_col=0)\n","general_inf_header = []\n","general_inf_content = []\n","general_inf_dict = {}\n","\n","for i in range(len(general_inf)):\n","    key = general_inf['Unnamed: 2'][i]\n","    val = general_inf['Unnamed: 1'][i]\n","    # The val need to be encapsulated inside a list\n","    general_inf_dict[key] = [val]\n","\n","df = pd.DataFrame(general_inf_dict)\n","CSV_FILE = '/content/drive/MyDrive/Program/Python/Data ML DL/Data Cleaning and Analyzing/IDX - Financial Statements Cleanup/company_general_information.csv'\n","\n","if os.path.exists(CSV_FILE):\n","    res_csv = pd.read_csv(CSV_FILE)\n","\n","    for j in range(len(res_csv)):\n","        # Use .iloc[] so the DataFrame can accept negative index\n","        if df['Entity code'][0] != res_csv['Entity code'].iloc[-1]:\n","            # mode='a' means to 'append', default was 'w' as in 'write'\n","            df.to_csv('company_general_information.csv', mode='a', header=False)\n","        elif df['Entity code'][0] != res_csv['Entity code'].iloc[j]:\n","            df.to_csv('company_general_information.csv', mode='a', header=False)\n","            break\n","        elif (\n","            df['Entity code'][0] == res_csv['Entity code'].iloc[j] and\n","            df['Current period start date'][0] != res_csv['Current period start date'].iloc[j]\n","        ):\n","            df.to_csv('company_general_information.csv', mode='a', header=False)\n","            break\n","else:\n","    df.to_csv('company_general_information.csv')"]},{"cell_type":"code","source":["!cp company_general_information.csv \"/content/drive/MyDrive/Program/Python/Data ML DL/Data Cleaning and Analyzing/IDX - Financial Statements Cleanup\""],"metadata":{"id":"XLGSajiyW3zT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Alternative Way To Do It\n","We're utilizing Python's standard libary `csv` here instead of `pandas`."],"metadata":{"id":"jYmIwwYIbL97"}},{"cell_type":"code","source":["FILENAME = \"/content/drive/MyDrive/Program/Python/Data ML DL/Datasets/IDX - Financial Statements/AALI/FinancialStatement-2021-I-AALI.xlsx\"\n","general_inf = pd.read_excel(FILENAME, sheet_name='1000000')\n","general_inf_header = []\n","general_inf_content = []\n","general_inf_dict = {}\n","\n","for i in range(len(general_inf)):\n","    general_inf_header.append(general_inf['Unnamed: 2'][i])\n","    general_inf_content.append(general_inf['Unnamed: 1'][i])\n","\n","with open('text.csv', 'w') as f:\n","    writer = csv.writer(f)\n","    writer.writerow(general_inf_header)\n","    writer.writerow(general_inf_content)"],"metadata":{"id":"ehWUDDVqaINn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp text.csv \"/content/drive/MyDrive/Program/Python/Data ML DL/Data Cleaning and Analyzing/IDX - Financial Statements Cleanup\""],"metadata":{"id":"YSbXDYltaksw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["general_inf_dict = {}\n","\n","for i in range(len(general_inf)):\n","    key = general_inf['Unnamed: 2'][i]\n","    val = general_inf['Unnamed: 1'][i]\n","    # The val need to be encapsulated inside a list\n","    general_inf_dict[key] = [val]\n","\n","df = pd.DataFrame(general_inf_dict)\n","df['Entity code'].iloc[-1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"b4lTZ2Elqatu","executionInfo":{"status":"ok","timestamp":1639632291675,"user_tz":-420,"elapsed":361,"user":{"displayName":"Mahardhika Dwi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18064939782869251856"}},"outputId":"0872e532-4adc-4dc6-aa78-b914032814e2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'AALI'"]},"metadata":{},"execution_count":85}]}]}