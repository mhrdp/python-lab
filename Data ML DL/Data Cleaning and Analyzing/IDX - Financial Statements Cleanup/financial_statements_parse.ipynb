{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36222,
     "status": "ok",
     "timestamp": 1641345645145,
     "user": {
      "displayName": "Mahardhika Dwi",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18064939782869251856"
     },
     "user_tz": -420
    },
    "id": "TGngZKFKoPtq",
    "outputId": "f446b350-d9f8-4988-e004-ea6e8b9269f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Al9rDs0nWPv",
    "outputId": "5981b32c-9882-4127-a4a6-c7de10d0819f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Context',\n",
       " '1000000',\n",
       " '1210000',\n",
       " '1321000',\n",
       " '1410000 1 CurrentYear',\n",
       " '1410000 2 PriorYear',\n",
       " '1510000',\n",
       " 'hidden',\n",
       " 'Token']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_in_1 = '../../Datasets/IDX - Financial Statements/AALI/FinancialStatement-2021-II-AALI.xlsx'\n",
    "file_out = './company_financial_position.csv'\n",
    "file = pd.read_csv(file_out)\n",
    "filter_file = file.loc[file['entity_code'] == 'AALI']\n",
    "filter_file['entity_code']\n",
    "\n",
    "sheet = pd.ExcelFile(file_in_1)\n",
    "sheet.sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "dWKJS5lie-ZS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Agriculture'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "class ExtractData:\n",
    "    def __init__(self, file_in):\n",
    "        self.file_in = file_in\n",
    "        self.file_out = None\n",
    "    \n",
    "    def _get_sheetname(self, file_in):\n",
    "        sheets = pd.ExcelFile(file_in)\n",
    "        return sheets.sheet_names\n",
    "    \n",
    "    def _general_inf_sheet(self, file_in):\n",
    "        sheet_name = self._get_sheetname(file_in)\n",
    "        sheet = sheet_name[1]\n",
    "        return sheet\n",
    "    \n",
    "    def _financial_pos_sheet(self, file_in):\n",
    "        sheet_name = self._get_sheetname(file_in)\n",
    "        sheet = sheet_name[2]\n",
    "        return sheet\n",
    "    \n",
    "    def _profit_or_loss_sheet(self, file_in):\n",
    "        sheet_name = self._get_sheetname(file_in)\n",
    "        sheet = sheet_name[3]\n",
    "        return sheet\n",
    "    \n",
    "    def _cashflow_sheet(self, file_in):\n",
    "        sheet_name = self._get_sheetname(file_in)\n",
    "        sheet = sheet_name[6]\n",
    "        return sheet\n",
    "    \n",
    "    def _get_company_name(self, file_in):\n",
    "        general_inf = self._general_inf_sheet(file_in)\n",
    "        \n",
    "        reader = pd.read_excel(file_in, sheet_name=general_inf)\n",
    "        dict_temp = {}\n",
    "\n",
    "        for i in range(len(reader)):\n",
    "            key = reader['Unnamed: 2'][i]\n",
    "            val = reader['Unnamed: 1'][i]\n",
    "            dict_temp[key] = [val]\n",
    "        \n",
    "        df = pd.DataFrame(dict_temp)\n",
    "        df = df.rename(\n",
    "            columns = {\n",
    "                'Entity code': 'entity_code',\n",
    "                'Level of rounding used in financial statements': 'rounding_level',\n",
    "                'Sector': 'sector',\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Use __getitem__ method, aka. [[...]] to return type(DataFrame), instead of type(series)\n",
    "        return df[['entity_code', 'rounding_level', 'sector']]\n",
    "        \n",
    "    def general_inf(self):\n",
    "        file_in = self.file_in\n",
    "        self.file_out = './company_general_information.csv'\n",
    "        \n",
    "        sheet = self._general_inf_sheet(self.file_in)\n",
    "        \n",
    "        # index_col=0 is to remove auto-generated index column\n",
    "        gen_inf = pd.read_excel(file_in, sheet_name=sheet, index_col=0)\n",
    "        gen_inf_dict = {}\n",
    "        \n",
    "        # Convert the initial dataframe into dictionary for cleaning\n",
    "        for i in range(len(gen_inf)):\n",
    "            key = gen_inf['Unnamed: 2'][i]\n",
    "            val = gen_inf['Unnamed: 1'][i]\n",
    "            gen_inf_dict[key] = [val]\n",
    "        \n",
    "        # Back to dataframe after cleaning\n",
    "        df = pd.DataFrame(gen_inf_dict)\n",
    "\n",
    "        # Rename the first dataframe header\n",
    "        df.columns.values[0] = 'date_of_report'\n",
    "        \n",
    "        # Rename entire columns\n",
    "        df = df.rename(columns={\n",
    "            'Entity name': 'entity_name',\n",
    "            'Entity code': 'entity_code',\n",
    "            'Explanation of change in name from the end of the preceding reporting period': 'name_change_explanation',\n",
    "            'Entity identification number': 'identification_number',\n",
    "            'Entity main industry': 'main_industry',\n",
    "            'Controlling shareholder information': 'information_control',\n",
    "            'Type of entity': 'entity_type',\n",
    "            'Type of listed securities': 'securities_type',\n",
    "            'Type of board on which the entity is listed': 'type_of_board',\n",
    "            'Whether the financial statements are of an individual entity or a group of entities': 'statements_from',\n",
    "            'Period of financial statements submissions': 'period',\n",
    "            'Current period start date': 'start_date',\n",
    "            'Current period end date': 'end_date',\n",
    "            'Prior period start date': 'prior_start_date',\n",
    "            'Prior period end date': 'prior_end_date',\n",
    "            'Description of presentation currency': 'currency',\n",
    "            'Conversion rate at reporting date if presentation currency is other than rupiah': 'alternate_currency',\n",
    "            'Level of rounding used in financial statements': 'rounding_level',\n",
    "            'Type of report on financial statements': 'report_type',\n",
    "            'Type of auditor\\'s opinion': 'auditor_opinion_type',\n",
    "            'Matters disclosed in emphasis-of-matter or other-matter paragraph, if any': 'emphasis_of_matter',\n",
    "            'Result of review engagement': 'review_result',\n",
    "            'Date of auditor\\'s opinion or result of review report': 'date_of_review',\n",
    "            'Name of current year audit signing partner': 'signing_partner_name',\n",
    "            'Number of years served as audit signing partner': 'signing_partner_experience',\n",
    "            'Name of prior year audit signing partner': 'prior_year_signing_partner',\n",
    "            'Whether in compliance with BAPEPAM LK VIII G 11 rules concerning responsibilities of board of directors on financial statements': 'BAPEPAM_LK_VIII_G11',\n",
    "            'Whether in compliance with BAPEPAM LK VIII A two rules concerning independence of accountant providing audit services in capital market': 'BAPEPAM_LK_VIII_A2',\n",
    "\n",
    "            'Sector': 'sector',\n",
    "            'Subsector': 'subsector',\n",
    "            'Prior year end date': 'prior_year_end',\n",
    "            'Current year auditor': 'current_year_auditor',\n",
    "            'Prior year auditor': 'prior_year_auditor',\n",
    "        })\n",
    "        df = df.drop(columns=['General information'])\n",
    "        \n",
    "        # If output .csv exist\n",
    "        if os.path.exists(self.file_out):\n",
    "            read_file_out = pd.read_csv(self.file_out)\n",
    "            \n",
    "            # Delete a row if that row has entity_code column empty and save it again\n",
    "            if True in list(read_file_out['entity_code'].isna()):\n",
    "                read_file_out.dropna(subset=['entity_code'], inplace=True)\n",
    "                read_file_out.reset_index(drop=True)\n",
    "                read_file_out.to_csv('./general_company_information.csv', index=False)\n",
    "            \n",
    "            # If emiten name not in the list\n",
    "            if df['entity_code'][0] not in list(set(read_file_out['entity_code'])):\n",
    "                # mode = 'a' is to append, default is 'w' to write\n",
    "                df.to_csv('./company_general_information.csv', mode='a', header=False, index=False)\n",
    "            \n",
    "            # If emiten name already inside the list\n",
    "            if df['entity_code'][0] in list(set(read_file_out['entity_code'])):\n",
    "                # Filter the dataframe based on entity_code\n",
    "                filtered_df = read_file_out.loc[read_file_out['entity_code'] == df['entity_code'][0]]\n",
    "                \n",
    "                # Compare the date_of_report with filtered dataframe\n",
    "                if df['date_of_report'][0] not in list(filtered_df['date_of_report']):\n",
    "                    df.to_csv('./company_general_information.csv', mode='a', header=False, index=False)\n",
    "        else:\n",
    "            # Create .csv if not exist\n",
    "            df.to_csv('./company_general_information.csv', index=False)\n",
    "    \n",
    "    def financial_pos(self):\n",
    "        sheet = self._financial_pos_sheet(self.file_in)\n",
    "        fin_pos = pd.read_excel(self.file_in, sheet_name=sheet, index_col=0)\n",
    "        self.file_out = './company_financial_position.csv'\n",
    "        \n",
    "        # Dataframe for basic company information\n",
    "        df_get_name = self._get_company_name(self.file_in)\n",
    "        \n",
    "        header = []\n",
    "        content = []\n",
    "        fin_dict = {}\n",
    "        \n",
    "        # Convert the initial dataframe into dictionary for some cleaning\n",
    "        for i in range(len(fin_pos)):\n",
    "            key = fin_pos['Unnamed: 3'][i]\n",
    "            val = fin_pos['Unnamed: 1'][i]\n",
    "            # The val need to be encapsulated inside a list\n",
    "            fin_dict[key] = [val]\n",
    "        \n",
    "        # Convert back into dataframe after cleaning\n",
    "        df = pd.DataFrame(fin_dict)\n",
    "        \n",
    "        # Rename the first column\n",
    "        df.columns.values[0] = 'date_of_report'\n",
    "\n",
    "        # Slice the dataframe with __getitem__ method aka. [[...]]\n",
    "        df = df[[\n",
    "                'date_of_report', 'Total current assets', 'Total non-current assets', 'Total assets',\n",
    "                'Total current liabilities', 'Total non-current liabilities', 'Total liabilities',\n",
    "                'Total equity', 'Total liabilities and equity',\n",
    "        ]]\n",
    "        \n",
    "        # Rename the entire columns\n",
    "        df = df.rename(\n",
    "            columns = {\n",
    "                'Total current assets': 'total_current_assets',\n",
    "                'Total non-current assets': 'total_noncurrent_assets',\n",
    "                'Total assets': 'total_assets',\n",
    "                'Total current liabilities': 'total_current_liabilities',\n",
    "                'Total non-current liabilities': 'total_noncurrent_liabilities',\n",
    "                'Total liabilities': 'total_liabilities',\n",
    "                'Total equity': 'total_equity',\n",
    "                'Total liabilities and equity': 'total_liabilities_and_equity',\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Combine the two dataframe\n",
    "        # axis=1 was to combine the DataFrames according to its index,\n",
    "        # instead of making new row for each data inside the DataFrames like the default behaviour\n",
    "        df = pd.concat([df_get_name, df], axis=1)\n",
    "        \n",
    "        # If corresponding .csv exist\n",
    "        if os.path.exists(self.file_out):\n",
    "            read_file_out = pd.read_csv(self.file_out)\n",
    "\n",
    "            # Delete a row if that row has entity_code column empty and save it again\n",
    "            if True in list(read_file_out['entity_code'].isna()):\n",
    "                read_file_out.dropna(subset=['entity_code'], inplace=True)\n",
    "                read_file_out.reset_index(drop=True)\n",
    "                read_file_out.to_csv('./company_financial_position.csv', index=False)\n",
    "            \n",
    "            # If entity_code in source dataframe not in corresponding .csv\n",
    "            if df['entity_code'][0] not in list(set(read_file_out['entity_code'])):\n",
    "                # mode = 'a' is to append, default is 'w' to write                \n",
    "                df.to_csv('./company_financial_position.csv', mode='a', header=False, index=False)\n",
    "            \n",
    "            # If entity_code inside the corresponding .csv\n",
    "            if df['entity_code'][0] in list(set(read_file_out['entity_code'])):\n",
    "                # Filter the corresponding .csv based in entity_code in source dataframe\n",
    "                filtered_df = read_file_out.loc[read_file_out['entity_code'] == df['entity_code'][0]]\n",
    "                \n",
    "                # Check whether the source dataframe's date_of_report already exist in output .csv\n",
    "                if df['date_of_report'][0] not in list(filtered_df['date_of_report']):\n",
    "                    df.to_csv('./company_financial_position.csv', mode='a', header=False, index=False)\n",
    "        else:\n",
    "            # If corresponding .csv not exist\n",
    "            df.to_csv('./company_financial_position.csv', index=False)\n",
    "\n",
    "    def profit_or_loss(self):\n",
    "        sheet = self._profit_or_loss_sheet(self.file_in)\n",
    "        df_get_name = self._get_company_name(self.file_in)\n",
    "        profit_loss = pd.read_excel(self.file_in, sheet_name=sheet, index_col=0)\n",
    "\n",
    "        self.file_out = './profit_or_loss.csv'\n",
    "        \n",
    "        # Convert the dataframe into a dataframe convertable dictionary\n",
    "        profit_loss_dict = {}\n",
    "        for i in range(len(profit_loss)):\n",
    "            key = profit_loss['Unnamed: 3'][i]\n",
    "            val = profit_loss['Unnamed: 1'][i]\n",
    "            profit_loss_dict[key] = [val]\n",
    "            \n",
    "        # Convert back to pandas Dataframe\n",
    "        df = pd.DataFrame(profit_loss_dict)\n",
    "        df.columns.values[0] = 'date_of_report'\n",
    "        \n",
    "        # Filter the irrelevant columns with .__getitem__ method aka. [[...]]\n",
    "        df = df[[\n",
    "            'date_of_report', 'Sales and revenue', 'Cost of sales and revenue',\n",
    "            'Total gross profit', 'Total profit (loss)', \n",
    "            'Total other comprehensive income, before tax','Total comprehensive income'\n",
    "        ]]\n",
    "        \n",
    "        # Rename the columns\n",
    "        df = df.rename(\n",
    "            columns = {\n",
    "                'Sales and revenue': 'sales_and_revenue',\n",
    "                'Cost of sales and revenue': 'cost',\n",
    "                'Total gross profit': 'gross_profit',\n",
    "                'Total profit (loss)': 'total_profit',\n",
    "                'Total other comprehensive income, before tax': 'comprehensive_income_before_tax',\n",
    "                'Total comprehensive income': 'total_comprehensive_income'\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Combine two dataframe\n",
    "        df = pd.concat([df_get_name, df], axis=1)\n",
    "\n",
    "        # Check if the output file already exist\n",
    "        if os.path.exists(self.file_out):\n",
    "            read_file_out = pd.read_csv(self.file_out)\n",
    "            \n",
    "            # Check whether inside the output file we have a blank column based on entity_code column\n",
    "            # and delete it\n",
    "            if True in list(read_file_out['entity_code'].isna()):\n",
    "                read_file_out.dropna(subset=['entity_code'], inplace=True)\n",
    "                read_file_out.reset_index(drop=True)\n",
    "                read_file_out.to_csv('./profit_or_loss.csv', index=False)\n",
    "            \n",
    "            if df['entity_code'][0] not in list(set(read_file_out['entity_code'])):\n",
    "                df.to_csv('./profit_or_loss.csv', mode='a', header=False, index=False)\n",
    "            \n",
    "            # Check whether entity_code from original dataframe has a duplicate in output file\n",
    "            if df['entity_code'][0] in list(set(read_file_out['entity_code'])):\n",
    "                \n",
    "                # Filter the output file based on original file entity_code\n",
    "                filtered_df = read_file_out.loc[read_file_out['entity_code'] == df['entity_code'][0]]\n",
    "\n",
    "                # Check the duplicates data by date_of_report if there's a duplicate entity_code\n",
    "                if df['date_of_report'][0] not in list(filtered_df['date_of_report']):\n",
    "                    df.to_csv('./profit_or_loss.csv', mode='a', header=False, index=False)\n",
    "        else:\n",
    "            df.to_csv('./profit_or_loss.csv', index=False)\n",
    "    \n",
    "    def cashflow(self):\n",
    "        sheet = self._cashflow_sheet(self.file_in)\n",
    "        df_get_name = self._get_company_name(self.file_in)\n",
    "        cashflow_sheet = pd.read_excel(self.file_in, sheet_name=sheet)\n",
    "        \n",
    "        self.file_out = './cashflow.csv'\n",
    "        \n",
    "        # Convert original dafaframe into dataframe convertable dictionary\n",
    "        cashflow_dict = {}\n",
    "        for i in range(len(cashflow_sheet)):\n",
    "            key = cashflow_sheet['Unnamed: 3'][i]\n",
    "            value = cashflow_sheet['Unnamed: 1'][i]\n",
    "            cashflow_dict[key] = [value]\n",
    "        \n",
    "        df = pd.DataFrame(cashflow_dict)\n",
    "        \n",
    "        # Rename the very first column\n",
    "        df.columns.values[0] = 'date_of_report'\n",
    "        \n",
    "        # Filter the dataframe using .__getitem__ methods aka. [[...]]\n",
    "        df = df[[\n",
    "            'date_of_report', 'Total net cash flows received from (used in) operating activities',\n",
    "            'Total net cash flows received from (used in) investing activities',\n",
    "            'Total net cash flows received from (used in) financing activities',\n",
    "            'Total net increase (decrease) in cash and cash equivalents',\n",
    "            'Cash and cash equivalents cash flows, beginning of the period',\n",
    "            'Effect of exchange rate changes on cash and cash equivalents',\n",
    "            'Other increase (decrease) in cash and cash equivalents',\n",
    "            'Cash and cash equivalents cash flows, end of the period',\n",
    "        ]]\n",
    "        \n",
    "        # Rename the columns\n",
    "        df = df.rename(\n",
    "            columns = {\n",
    "                'Total net cash flows received from (used in) operating activities': 'cashflow_from_operating',\n",
    "                'Total net cash flows received from (used in) investing activities': 'cashflow_from_investing',\n",
    "                'Total net cash flows received from (used in) financing activities': 'cashflow_from_financing',\n",
    "                'Total net increase (decrease) in cash and cash equivalents': 'change_in_cash_and_equivalents',\n",
    "                'Cash and cash equivalents cash flows, beginning of the period': 'cash_and_equivalents_start',\n",
    "                'Effect of exchange rate changes on cash and cash equivalents': 'exchange_rate_effect',\n",
    "                'Other increase (decrease) in cash and cash equivalents': 'other_change_in_cash_or_equivalents',\n",
    "                'Cash and cash equivalents cash flows, end of the period': 'cash_or_equivalents_final',\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Combine two dataframe\n",
    "        df = pd.concat([df_get_name, df], axis=1)\n",
    "        \n",
    "        if os.path.exists(self.file_out):\n",
    "            read_file_out = pd.read_csv(self.file_out)\n",
    "            \n",
    "            if True in list(read_file_out['entity_code'].isna()):\n",
    "                read_file_out.dropna(subset=['entity_code'], inplace=True)\n",
    "                read_file_out.reset_index(drop=True)\n",
    "                read_file_out.to_csv('./cashflow.csv', index=False)\n",
    "            \n",
    "            if df['entity_code'][0] not in list(set(read_file_out['entity_code'])):\n",
    "                df.to_csv('./cashflow.csv', index=False, header=False)\n",
    "            \n",
    "            if df['entity_code'][0] in list(set(read_file_out['entity_code'])):\n",
    "                filtered_df = read_file_out.loc[read_file_out['entity_code'] == df['entity_code'][0]]\n",
    "                if df['date_of_report'][0] not in list(filtered_df['date_if_report']):\n",
    "                    df.to_csv('./cashflow.csv', index=False, header=False)\n",
    "        else:\n",
    "            df.to_csv('./cashflow.csv', index=False)\n",
    "\n",
    "file_in_1 = '../../Datasets/IDX - Financial Statements/ABBA/FinancialStatement-2021-I-ABBA.xlsx'\n",
    "file_in_2 = '../../Datasets/IDX - Financial Statements/AALI/FinancialStatement-2021-I-AALI.xlsx'\n",
    "file_in_3 = '../../Datasets/IDX - Financial Statements/AALI/FinancialStatement-2021-II-AALI.xlsx'\n",
    "init = ExtractData(file_in_3)\n",
    "init._get_company_name(file_in_3)['sector'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1639899531845,
     "user": {
      "displayName": "Mahardhika Dwi",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18064939782869251856"
     },
     "user_tz": -420
    },
    "id": "ABy1hnOqKgGM",
    "outputId": "a7f91768-e5bf-477f-c651-e054319e2e5a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'cp' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Run this to save .csv after above cells if you executed this notebook from Google Colab\n",
    "!cp profit_or_loss.csv \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 1143,
     "status": "ok",
     "timestamp": 1639896929918,
     "user": {
      "displayName": "Mahardhika Dwi",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18064939782869251856"
     },
     "user_tz": -420
    },
    "id": "FofAzNC8qGEA",
    "outputId": "a012c24d-894a-4c4a-ff8a-ab3b240165bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'30 June 2021'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "\n",
    "FILENAME = \"../../Datasets/IDX - Financial Statements/AALI/FinancialStatement-2021-II-AALI.xlsx\"\n",
    "fin_pos = pd.read_excel(FILENAME, sheet_name='1210000', index_col=0)\n",
    "header = []\n",
    "content = []\n",
    "fin_dict = {}\n",
    "\n",
    "for i in range(len(fin_pos)):\n",
    "    key = fin_pos['Unnamed: 3'][i]\n",
    "    val = fin_pos['Unnamed: 1'][i]\n",
    "    # The val need to be encapsulated inside a list\n",
    "    fin_dict[key] = [val]\n",
    "\n",
    "df = pd.DataFrame(fin_dict)\n",
    "df.columns.values[0] = 'date_of_report'\n",
    "\n",
    "df_trim = df[[\n",
    "        'date_of_report', 'Total current assets', 'Total non-current assets', 'Total assets',\n",
    "        'Total current liabilities', 'Total non-current liabilities', 'Total liabilities',\n",
    "        'Total equity', 'Total liabilities and equity',\n",
    "]]\n",
    "\n",
    "CSV_FILE = './company_financial_position.csv'\n",
    "\n",
    "read_csv = pd.read_csv(CSV_FILE)\n",
    "df_trim['date_of_report'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-IcLKkYbdgW"
   },
   "source": [
    "# Using `pandas` Library\n",
    "Before export it to `.csv`, we need to convert the data into `pandas` `DataFrame` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MWBH9sSiRS5C"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "\n",
    "FILENAME = \"/content/drive/MyDrive/Program/Python/Data ML DL/Datasets/IDX - Financial Statements/AALI/FinancialStatement-2021-I-AALI.xlsx\"\n",
    "general_inf = pd.read_excel(FILENAME, sheet_name='1000000', index_col=0)\n",
    "general_inf_header = []\n",
    "general_inf_content = []\n",
    "general_inf_dict = {}\n",
    "\n",
    "for i in range(len(general_inf)):\n",
    "    key = general_inf['Unnamed: 2'][i]\n",
    "    val = general_inf['Unnamed: 1'][i]\n",
    "    # The val need to be encapsulated inside a list\n",
    "    general_inf_dict[key] = [val]\n",
    "\n",
    "df = pd.DataFrame(general_inf_dict)\n",
    "CSV_FILE = '/content/drive/MyDrive/Program/Python/Data ML DL/Data Cleaning and Analyzing/IDX - Financial Statements Cleanup/company_general_information.csv'\n",
    "\n",
    "if os.path.exists(CSV_FILE):\n",
    "    res_csv = pd.read_csv(CSV_FILE)\n",
    "\n",
    "    for j in range(len(res_csv)):\n",
    "        # Use .iloc[] so the DataFrame can accept negative index\n",
    "        if df['Entity code'][0] != res_csv['Entity code'].iloc[-1]:\n",
    "            # mode='a' means to 'append', default was 'w' as in 'write'\n",
    "            df.to_csv('company_general_information.csv', mode='a', header=False)\n",
    "        elif df['Entity code'][0] != res_csv['Entity code'].iloc[j]:\n",
    "            df.to_csv('company_general_information.csv', mode='a', header=False)\n",
    "            break\n",
    "        elif (\n",
    "            df['Entity code'][0] == res_csv['Entity code'].iloc[j] and\n",
    "            df['Current period start date'][0] != res_csv['Current period start date'].iloc[j]\n",
    "        ):\n",
    "            df.to_csv('company_general_information.csv', mode='a', header=False)\n",
    "            break\n",
    "else:\n",
    "    df.to_csv('company_general_information.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XLGSajiyW3zT"
   },
   "outputs": [],
   "source": [
    "!cp company_general_information.csv \"/content/drive/MyDrive/Program/Python/Data ML DL/Data Cleaning and Analyzing/IDX - Financial Statements Cleanup\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYmIwwYIbL97"
   },
   "source": [
    "# Alternative Way To Do It\n",
    "We're utilizing Python's standard libary `csv` here instead of `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ehWUDDVqaINn"
   },
   "outputs": [],
   "source": [
    "FILENAME = \"/content/drive/MyDrive/Program/Python/Data ML DL/Datasets/IDX - Financial Statements/AALI/FinancialStatement-2021-I-AALI.xlsx\"\n",
    "general_inf = pd.read_excel(FILENAME, sheet_name='1000000')\n",
    "general_inf_header = []\n",
    "general_inf_content = []\n",
    "general_inf_dict = {}\n",
    "\n",
    "for i in range(len(general_inf)):\n",
    "    general_inf_header.append(general_inf['Unnamed: 2'][i])\n",
    "    general_inf_content.append(general_inf['Unnamed: 1'][i])\n",
    "\n",
    "with open('text.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(general_inf_header)\n",
    "    writer.writerow(general_inf_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YSbXDYltaksw"
   },
   "outputs": [],
   "source": [
    "!cp text.csv \"/content/drive/MyDrive/Program/Python/Data ML DL/Data Cleaning and Analyzing/IDX - Financial Statements Cleanup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 361,
     "status": "ok",
     "timestamp": 1639632291675,
     "user": {
      "displayName": "Mahardhika Dwi",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18064939782869251856"
     },
     "user_tz": -420
    },
    "id": "b4lTZ2Elqatu",
    "outputId": "0872e532-4adc-4dc6-aa78-b914032814e2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'AALI'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general_inf_dict = {}\n",
    "\n",
    "for i in range(len(general_inf)):\n",
    "    key = general_inf['Unnamed: 2'][i]\n",
    "    val = general_inf['Unnamed: 1'][i]\n",
    "    # The val need to be encapsulated inside a list\n",
    "    general_inf_dict[key] = [val]\n",
    "\n",
    "df = pd.DataFrame(general_inf_dict)\n",
    "df['Entity code'].iloc[-1]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "financial_statements_parse.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
