{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Pytorch quickstart official.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMrFRW5omYzJYkMPmlvEKJK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"SWP_L-dzUYjI"},"source":["# This is a PyTorch Tutorial from PyTorch Official Site\n","link: [quickstart](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html)"]},{"cell_type":"code","metadata":{"id":"6IV2MWYe5h46","executionInfo":{"status":"ok","timestamp":1629386739319,"user_tz":-420,"elapsed":3527,"user":{"displayName":"Mahardhika Dwi","photoUrl":"","userId":"18064939782869251856"}}},"source":["import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor, Lambda, Compose\n","import matplotlib.pyplot as plt"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z9Z-qd72FG7d"},"source":["PyTorch offers domain-specific libraries such as \n","\n","1. [TorchText](https://pytorch.org/text/stable/index.html), \n","2. [TorchVision](https://pytorch.org/text/stable/index.html), and \n","3. [TorchAudio](https://pytorch.org/text/stable/index.html)\n","\n","all of which include datasets. For this tutorial, we will be using a TorchVision dataset.\n","\n","The `torchvision.datasets` module contains `Dataset` objects for many real-world vision data like **CIFAR**, **COCO** ([full list here](https://pytorch.org/text/stable/index.html)). In this tutorial, we use the `FashionMNIST` dataset. Every TorchVision `Dataset` includes two arguments: `transform` and `target_transform` to modify the samples and labels respectively."]},{"cell_type":"code","metadata":{"id":"UoavPuTFBOX2","executionInfo":{"status":"ok","timestamp":1629387100307,"user_tz":-420,"elapsed":342,"user":{"displayName":"Mahardhika Dwi","photoUrl":"","userId":"18064939782869251856"}}},"source":["# Download training data from dataset\n","training_data = datasets.FashionMNIST(\n","    root='data',\n","    train=True,\n","    download=True,\n","    transform=ToTensor(),\n",")\n","\n","# Download test data from dataset\n","test_data = datasets.FashionMNIST(\n","    root='data',\n","    train=False,\n","    download=True,\n","    transform=ToTensor(),\n",")"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qlw1yoReE0W5"},"source":["We pass the `Dataset` as an argument to `DataLoader`. This wraps an iterable over our dataset, and supports automatic batching, sampling, shuffling and multiprocess data loading. Here we define a **batch size of 64**, i.e. each element in the dataloader iterable will return a batch of 64 features and labels."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iarvtXtPCpq_","executionInfo":{"status":"ok","timestamp":1629387670743,"user_tz":-420,"elapsed":368,"user":{"displayName":"Mahardhika Dwi","photoUrl":"","userId":"18064939782869251856"}},"outputId":"a6e29bba-0181-4553-d634-3e1dc9958e33"},"source":["batch_size = 64\n","\n","# Create data loader\n","train_dataloader = DataLoader(training_data, batch_size=batch_size)\n","test_dataloader = DataLoader(training_data, batch_size=batch_size)\n","\n","for X, y in test_dataloader:\n","    print('Shape of X [N, C, H, W]:', X.shape)\n","    print('Shape of y:', y.shape, y.dtype)\n","    break"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n","Shape of y: torch.Size([64]) torch.int64\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"q9Z6uD7jGeGa"},"source":["# Creating Models\n","To define a neural network in PyTorch, we create a class that inherits from [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html). We define the layers of the network in the `__init__` function and specify how data will pass through the network in the `forward` function. To accelerate operations in the neural network, we move it to the GPU if available."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rIKQvFmGHK0N","executionInfo":{"status":"ok","timestamp":1629388930470,"user_tz":-420,"elapsed":366,"user":{"displayName":"Mahardhika Dwi","photoUrl":"","userId":"18064939782869251856"}},"outputId":"0003380d-149f-42cd-d02e-92b883712a6b"},"source":["# Get CPU or GPU device for training\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print('using {} device'.format(device))\n","\n","# Define model\n","class NeuralNetwork(nn.Module):\n","    def __init__(self):\n","        super(NeuralNetwork, self).__init__()\n","        self.flatten = nn.Flatten()\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(28*28, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 10),\n","            nn.ReLU()\n","        )\n","    \n","    def forward(self, x):\n","        x = self.flatten(x)\n","        logits = self.linear_relu_stack(x)\n","        return logits\n","model = NeuralNetwork().to(device)\n","print(model)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["using cpu device\n","NeuralNetwork(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (linear_relu_stack): Sequential(\n","    (0): Linear(in_features=784, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=512, out_features=512, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=512, out_features=10, bias=True)\n","    (5): ReLU()\n","  )\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PF67hXtyLC94"},"source":["## Optimizing the Model Parameters\n","To train model, we need [loss function](https://pytorch.org/docs/stable/nn.html#loss-functions) and [optimizer](https://pytorch.org/docs/stable/optim.html)."]},{"cell_type":"code","metadata":{"id":"YUBIFPHoLw7s","executionInfo":{"status":"ok","timestamp":1629389822821,"user_tz":-420,"elapsed":396,"user":{"displayName":"Mahardhika Dwi","photoUrl":"","userId":"18064939782869251856"}}},"source":["loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8lXeflC0M6Qv"},"source":["In a single training loop, the model makes predictions on the training dataset (fed to it in batches), and backpropagates the prediction error to adjust the model’s parameters."]},{"cell_type":"code","metadata":{"id":"JEG5wH52NAk3","executionInfo":{"status":"ok","timestamp":1629390541379,"user_tz":-420,"elapsed":381,"user":{"displayName":"Mahardhika Dwi","photoUrl":"","userId":"18064939782869251856"}}},"source":["def train(dataloader, model, loss_fn, optimizer):\n","    size = len(dataloader.dataset)\n","    for batch, (X, y) in enumerate(dataloader):\n","        X, y = X.to(device), y.to(device)\n","\n","        # Compute prediction error\n","        pred = model(X)\n","        loss = loss_fn(pred, y)\n","\n","        # Backpropagation\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if batch % 100 == 0:\n","            loss, current = loss.item(), batch * len(X)\n","            print(f'loss: {loss:>7f} [{current:>5d}/{size:>5d}]')"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OFZBEwjnP7yF"},"source":["We also check the model’s performance against the test dataset to ensure it is learning."]},{"cell_type":"code","metadata":{"id":"bBViidVPQBzS","executionInfo":{"status":"ok","timestamp":1629391286342,"user_tz":-420,"elapsed":351,"user":{"displayName":"Mahardhika Dwi","photoUrl":"","userId":"18064939782869251856"}}},"source":["def test(dataloader, model, loss_fn):\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","    model.eval()\n","\n","    test_loss, correct = 0, 0\n","    with torch.no_grad():\n","        for X, y in dataloader:\n","            X, y = X.to(device), y.to(device)\n","            pred = model(X)\n","            test_loss += loss_fn(pred, y).item()\n","            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","    test_loss /= num_batches\n","    correct /= size\n","    print(f'Test error: \\n Accuracy: {(100*correct):>0.1f}%, Avg. Loss: {test_loss:>8f} \\n')"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3CIOuYZeSjgv"},"source":["The training process is conducted over several iterations (**epochs**). During each **epoch**, the model learns parameters to make better predictions. We print the model’s accuracy and loss at each epoch; we’d like to see the accuracy increase and the loss decrease with every epoch."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aPltPzkgSul0","executionInfo":{"status":"ok","timestamp":1629391543551,"user_tz":-420,"elapsed":74622,"user":{"displayName":"Mahardhika Dwi","photoUrl":"","userId":"18064939782869251856"}},"outputId":"2fd63297-f59a-4547-dc1b-2a3a29d204c9"},"source":["epoch = 5\n","\n","for t in range(epoch):\n","    print(f'Epoch {t+1}\\n------------------------------')\n","    train(train_dataloader, model, loss_fn, optimizer)\n","    test(train_dataloader, model, loss_fn)\n","print('Done')"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Epoch 1\n","------------------------------\n","loss: 2.306065 [    0/60000]\n","loss: 2.295849 [ 6400/60000]\n","loss: 2.292001 [12800/60000]\n","loss: 2.288401 [19200/60000]\n","loss: 2.268022 [25600/60000]\n","loss: 2.265650 [32000/60000]\n","loss: 2.267147 [38400/60000]\n","loss: 2.247698 [44800/60000]\n","loss: 2.256712 [51200/60000]\n","loss: 2.233366 [57600/60000]\n","Test error: \n"," Accuracy: 49.2%, Avg. Loss: 2.224048 \n","\n","Epoch 2\n","------------------------------\n","loss: 2.243088 [    0/60000]\n","loss: 2.227201 [ 6400/60000]\n","loss: 2.204577 [12800/60000]\n","loss: 2.212039 [19200/60000]\n","loss: 2.153504 [25600/60000]\n","loss: 2.156748 [32000/60000]\n","loss: 2.174996 [38400/60000]\n","loss: 2.129626 [44800/60000]\n","loss: 2.164420 [51200/60000]\n","loss: 2.105088 [57600/60000]\n","Test error: \n"," Accuracy: 50.0%, Avg. Loss: 2.087146 \n","\n","Epoch 3\n","------------------------------\n","loss: 2.137674 [    0/60000]\n","loss: 2.106386 [ 6400/60000]\n","loss: 2.046973 [12800/60000]\n","loss: 2.070414 [19200/60000]\n","loss: 1.934612 [25600/60000]\n","loss: 1.946007 [32000/60000]\n","loss: 2.000894 [38400/60000]\n","loss: 1.892408 [44800/60000]\n","loss: 1.959073 [51200/60000]\n","loss: 1.895534 [57600/60000]\n","Test error: \n"," Accuracy: 50.4%, Avg. Loss: 1.829309 \n","\n","Epoch 4\n","------------------------------\n","loss: 1.899529 [    0/60000]\n","loss: 1.850734 [ 6400/60000]\n","loss: 1.719594 [12800/60000]\n","loss: 1.818145 [19200/60000]\n","loss: 1.621245 [25600/60000]\n","loss: 1.636557 [32000/60000]\n","loss: 1.741744 [38400/60000]\n","loss: 1.569766 [44800/60000]\n","loss: 1.645818 [51200/60000]\n","loss: 1.601743 [57600/60000]\n","Test error: \n"," Accuracy: 52.5%, Avg. Loss: 1.510555 \n","\n","Epoch 5\n","------------------------------\n","loss: 1.591526 [    0/60000]\n","loss: 1.550562 [ 6400/60000]\n","loss: 1.373248 [12800/60000]\n","loss: 1.506760 [19200/60000]\n","loss: 1.318004 [25600/60000]\n","loss: 1.350936 [32000/60000]\n","loss: 1.445725 [38400/60000]\n","loss: 1.288732 [44800/60000]\n","loss: 1.343727 [51200/60000]\n","loss: 1.301746 [57600/60000]\n","Test error: \n"," Accuracy: 63.3%, Avg. Loss: 1.245129 \n","\n","Done\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RjMnHnd0Tiak"},"source":["# Saving Models\n","A common way to save a model is to serialize the internal state dictionary (containing the model parameters)."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IUiqNe59TpBo","executionInfo":{"status":"ok","timestamp":1629391648138,"user_tz":-420,"elapsed":339,"user":{"displayName":"Mahardhika Dwi","photoUrl":"","userId":"18064939782869251856"}},"outputId":"9da37c06-4e8b-482c-ef73-c1e11c610de8"},"source":["torch.save(model.state_dict(), 'model.pth')\n","print('Saved PyTorch model into model.pth')"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Saved PyTorch model into model.pth\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"K510E2_2T7wk"},"source":["## Loading Model\n","The process for loading a model includes re-creating the model structure and loading the state dictionary into it."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c27tdVB0UAYw","executionInfo":{"status":"ok","timestamp":1629391704747,"user_tz":-420,"elapsed":396,"user":{"displayName":"Mahardhika Dwi","photoUrl":"","userId":"18064939782869251856"}},"outputId":"67240aa2-3a4f-4ef0-f0ab-9a523df0faf9"},"source":["model = NeuralNetwork()\n","model.load_state_dict(torch.load(\"model.pth\"))"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"_acEursnUHUr"},"source":["This model can now be used to make predictions."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iU-VpqbuUJ-8","executionInfo":{"status":"ok","timestamp":1629391751188,"user_tz":-420,"elapsed":382,"user":{"displayName":"Mahardhika Dwi","photoUrl":"","userId":"18064939782869251856"}},"outputId":"6e1f3ae6-1c59-4815-f862-81a36b5723e6"},"source":["classes = [\n","    \"T-shirt/top\",\n","    \"Trouser\",\n","    \"Pullover\",\n","    \"Dress\",\n","    \"Coat\",\n","    \"Sandal\",\n","    \"Shirt\",\n","    \"Sneaker\",\n","    \"Bag\",\n","    \"Ankle boot\",\n","]\n","\n","model.eval()\n","x, y = test_data[0][0], test_data[0][1]\n","with torch.no_grad():\n","    pred = model(x)\n","    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n","    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"],"name":"stdout"}]}]}